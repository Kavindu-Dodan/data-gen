# config.yaml - full example for Data Generator

input:
  type: LOGS              # Input type: LOGS, METRICS, ALB, NLB, VPC, CLOUDTRAIL, WAF, CLOUDTRAIL, AZURE_RESOURCE_LOGS
  delay: 500ms            # Delay between each data point (eg: 500ms)
  batching: 10s           # Emit generated data batched within 10 seconds (consider 0s for CloudWatch)
  max_batch_size: 10000   # Max batch size in bytes (eg: 10,000 bytes)
  max_data_points: 10000  # Max data points to emit after which program exits (eg: 10000 data points)
  max_runtime: 1h         # Max runtime for the input (eg: 1 hour)
output:
  wait_for_completion: true/false # wait for all data to output. Default is true.

## FILE output example
# type: FILE
# config:
#   location: "./data"           # Output file location, default "./out" with numeric suffixes for batching

## S3 output example
# type: S3
# config:
#   s3_bucket: "testing-bucket" # S3 bucket name (required)
#   compression: gzip           # Compression format; supports gzip
#   path_prefix: "logFile-"     # Optional prefix for bucket entries; defaults to "logFile-"

## FIREHOSE output example
# type: FIREHOSE
# config:
#   stream_name: "my-firehose-stream"  # Firehose stream name (required)

## CLOUDWATCH_LOG output example
# type: CLOUDWATCH_LOG
# config:
#   log_group: "MyGroup"          # CloudWatch log group name
#   log_stream: "data"            # CloudWatch log stream name

## Azure Resource logs output example
# type: AZURE_RESOURCE_LOGS
# config:
#  connection_string: "<Connection String>"  # Connection string for Azure Resource Logs
#  event_hub_name: "<Event Hub Name>"        # Event Hub name

## AWS configuration
#
# aws:
#  region: "us-east-1"
#  profile: "default"
